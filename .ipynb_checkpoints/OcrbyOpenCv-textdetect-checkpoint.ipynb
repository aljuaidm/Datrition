{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://nanonets.com/blog/deep-learning-ocr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Loading the necessary packages \n",
    "import numpy as np\n",
    "import cv2\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import pytesseract\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda install -c conda-forge tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating argument dictionary for the default arguments needed in the code. \n",
    "# The EAST text requires that your input image dimensions be multiples of 32\n",
    "args = {\"image\":\"./images/764126_box.jpg\",\n",
    "        \"east\":\"./opencv-text-detection/frozen_east_text_detection.pb\", \"min_confidence\":0.2,\n",
    "        \"width\":800, \"height\":800}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.2) /Users/travis/build/skvark/opencv-python/opencv/modules/dnn/src/caffe/caffe_io.cpp:1132: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"./opencv-text-detection/frozen_east_text_detection.pb\" in function 'ReadProtoFromBinaryFile'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0860700a0cb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# load the pre-trained EAST model for text detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"east\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# We would like to get two outputs from the EAST model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /Users/travis/build/skvark/opencv-python/opencv/modules/dnn/src/caffe/caffe_io.cpp:1132: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"./opencv-text-detection/frozen_east_text_detection.pb\" in function 'ReadProtoFromBinaryFile'\n"
     ]
    }
   ],
   "source": [
    "#Give location of the image to be read.\n",
    "#\"Example-images/ex24.jpg\" image is being loaded here. \n",
    "\n",
    "#args['image']=\"image\"\n",
    "image = cv2.imread(args['image'])\n",
    "\n",
    "#Saving a original image and shape\n",
    "orig = image.copy()\n",
    "(origH, origW) = image.shape[:2]\n",
    "\n",
    "# set the new height and width to default 320 by using args #dictionary.  \n",
    "(newW, newH) = (args[\"width\"], args[\"height\"])\n",
    "\n",
    "#Calculate the ratio between original and new image for both height and weight. \n",
    "#This ratio will be used to translate bounding box location on the original image. \n",
    "rW = origW / float(newW)\n",
    "rH = origH / float(newH)\n",
    "\n",
    "# resize the original image to new dimensions\n",
    "image = cv2.resize(image, (newW, newH))\n",
    "(H, W) = image.shape[:2]\n",
    "\n",
    "# construct a blob from the image to forward pass it to EAST model\n",
    "blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),\n",
    "(123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "\n",
    "# load the pre-trained EAST model for text detection \n",
    "net = cv2.dnn.readNet(args[\"east\"])\n",
    "\n",
    "# We would like to get two outputs from the EAST model. \n",
    "#1. Probabilty scores for the region whether that contains text or not. \n",
    "#2. Geometry of the text -- Coordinates of the bounding box detecting a text\n",
    "# The following two layer need to pulled from EAST model for achieving this. \n",
    "layerNames = [\n",
    "\"feature_fusion/Conv_7/Sigmoid\",\n",
    "\"feature_fusion/concat_3\"]\n",
    "#Loading Pre-trained EAST model and defining output layers\n",
    "#Forward pass the blob from the image to get the desired output layers\n",
    "net.setInput(blob)\n",
    "(scores, geometry) = net.forward(layerNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Returns a bounding box and probability score if it is more than minimum confidence\n",
    "def predictions(prob_score, geo):\n",
    "    (numR, numC) = prob_score.shape[2:4]\n",
    "    boxes = []\n",
    "    confidence_val = []\n",
    "\n",
    "# loop over rows\n",
    "    for y in range(0, numR):\n",
    "        scoresData = prob_score[0, 0, y]\n",
    "        x0 = geo[0, 0, y]\n",
    "        x1 = geo[0, 1, y]\n",
    "        x2 = geo[0, 2, y]\n",
    "        x3 = geo[0, 3, y]\n",
    "        anglesData = geo[0, 4, y]\n",
    "\n",
    "    # loop over the number of columns\n",
    "        for i in range(0, numC):\n",
    "            if scoresData[i] < args[\"min_confidence\"]:\n",
    "                continue\n",
    "\n",
    "            (offX, offY) = (i * 4.0, y * 4.0)\n",
    "\n",
    "            # extracting the rotation angle for the prediction and computing the sine and cosine\n",
    "            angle = anglesData[i]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "\n",
    "            # using the geo volume to get the dimensions of the bounding box\n",
    "            h = x0[i] + x2[i]\n",
    "            w = x1[i] + x3[i]\n",
    "\n",
    "            # compute start and end for the text pred bbox\n",
    "            endX = int(offX + (cos * x1[i]) + (sin * x2[i]))\n",
    "            endY = int(offY - (sin * x1[i]) + (cos * x2[i]))\n",
    "            startX = int(endX - w)\n",
    "            startY = int(endY - h)\n",
    "\n",
    "            boxes.append((startX, startY, endX, endY))\n",
    "            confidence_val.append(scoresData[i])\n",
    "\n",
    "# return bounding boxes and associated confidence_val\n",
    "    return (boxes, confidence_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-afcee958024c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Find predictions and  apply non-maxima suppression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidence_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeometry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnon_max_suppression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfidence_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    }
   ],
   "source": [
    "# Find predictions and  apply non-maxima suppression\n",
    "(boxes, confidence_val) = predictions(scores, geometry)\n",
    "boxes = non_max_suppression(np.array(boxes), probs=confidence_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'boxes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4453b78c10b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# loop over the bounding boxes to find the coordinate of bounding boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstartX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstartY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# scale the coordinates based on the respective ratios in order to reflect bounding box on the original image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstartX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartX\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'boxes' is not defined"
     ]
    }
   ],
   "source": [
    "##Text Detection and Recognition \n",
    "\n",
    "# initialize the list of results\n",
    "results = []\n",
    "\n",
    "# loop over the bounding boxes to find the coordinate of bounding boxes\n",
    "for (startX, startY, endX, endY) in boxes:\n",
    "# scale the coordinates based on the respective ratios in order to reflect bounding box on the original image\n",
    "    startX = int(startX * rW)\n",
    "    startY = int(startY * rH)\n",
    "    endX = int(endX * rW)\n",
    "    endY = int(endY * rH)\n",
    "\n",
    "#extract the region of interest\n",
    "    r = orig[startY:endY, startX:endX]\n",
    "\n",
    "#configuration setting to convert image to string.  \n",
    "    configuration = (\"-l eng --oem 1 --psm 8\")\n",
    "    ##This will recognize the text from the image of bounding box\n",
    "    text = pytesseract.image_to_string(r, config=configuration)\n",
    "\n",
    "    # append bbox coordinate and associated text to the list of results \n",
    "    results.append(((startX, startY, endX, endY), text))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'orig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7bfcbc635918>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Display the image with bounding box and recognized text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0morig_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Moving over the results and display on the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'orig' is not defined"
     ]
    }
   ],
   "source": [
    "#Display the image with bounding box and recognized text\n",
    "orig_image = orig.copy()\n",
    "\n",
    "# Moving over the results and display on the image\n",
    "for ((start_X, start_Y, end_X, end_Y), text) in results:\n",
    "    # display the text detected by Tesseract\n",
    "    print(\"{}\\n\".format(text))\n",
    "\n",
    "    # Displaying text\n",
    "    text = \"\".join([x if ord(x) < 128 else \"\" for x in text]).strip()\n",
    "    cv2.rectangle(orig_image, (start_X, start_Y), (end_X, end_Y),\n",
    "        (0, 0, 255), 2)\n",
    "    cv2.putText(orig_image, text, (start_X, start_Y - 30),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,0, 255), 2)\n",
    "\n",
    "plt.imshow(orig_image)\n",
    "plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
