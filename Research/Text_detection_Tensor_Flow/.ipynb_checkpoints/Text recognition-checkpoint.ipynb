{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'jpg']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"./images_sample/\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D,BatchNormalization\n",
    "from keras.layers import MaxPooling2D,Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0fb507b8d05f98844507569ba23f846a5929403c"
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "ed7dfb86d7e42bfb12104c6a0f261e90f202c262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 50, 50, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 25, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 25, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 62)                31806     \n",
      "=================================================================\n",
      "Total params: 2,670,846\n",
      "Trainable params: 2,669,822\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/Datrition/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=62)`\n"
     ]
    }
   ],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape = (50, 50,1), activation = 'relu',padding='same'))\n",
    "# Adding a second convolutional layer\n",
    "#classifier.add(BatchNormalization(axis=1))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "classifier.add(Convolution2D(64, (3, 3), activation = 'relu',padding='same'))\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Convolution2D(64, (3, 3), activation = 'relu',padding='same'))\n",
    "#classifier.add(BatchNormalization(axis=1))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "classifier.add(Convolution2D(128, (3, 3), activation = 'relu',padding='same'))\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Convolution2D(128, (3, 3), activation = 'relu',padding='same'))\n",
    "#classifier.add(BatchNormalization(axis=1))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(512,activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(0.5))\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(output_dim = 62, activation = 'softmax'))\n",
    "\n",
    "# Compiling the CNN\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "classifier.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5ffdc6c72c61e3a9b0d3597428c0b7496e8810eb"
   },
   "source": [
    "# Fitting Image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "0b4685510213dfbfeab1428518542e1af57e9e47",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 436 images belonging to 1 classes.\n",
      "Epoch 1/5\n",
      "40/40 [==============================] - 120s 3s/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "40/40 [==============================] - 118s 3s/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "40/40 [==============================] - 115s 3s/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "40/40 [==============================] - 120s 3s/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "40/40 [==============================] - 113s 3s/step - loss: 0.0036 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a546d87f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   shear_range=0.2,\n",
    "\n",
    "                                  )\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('./images_sample/',\n",
    "                                                target_size = (50,50),\n",
    "                                               batch_size = 128,\n",
    "                                                 color_mode= \"grayscale\",\n",
    "                                              class_mode = 'categorical')\n",
    "\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                         epochs = 5,\n",
    "                         steps_per_epoch=40,\n",
    "                         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1e340fdf04229c9ee15d2f7d51a9de028dcf8277"
   },
   "source": [
    "# Preprocessing the text doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "_uuid": "114ed7cc742a0c59bedcbe8ceca62d7fec8aa4ce",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "img=cv2.imread('../Box_detection_2/images/764216_bag.jpg')\n",
    "imagee=img.copy()\n",
    "img=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "ret,img=cv2.threshold(img,180,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "k=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "\n",
    "img = cv2.morphologyEx(img, cv2.MORPH_OPEN, k)\n",
    "k1=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(1,1))\n",
    "img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, k)\n",
    "\n",
    "img1=cv2.Canny(img,0,255,2)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(img1,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "img2=cv2.cvtColor(img1,cv2.COLOR_GRAY2BGR)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "img3=cv2.drawContours(img2, contours, -1, (0,255,255), 1)\n",
    "image=[]\n",
    "p=[]\n",
    "list=['0','1','2','3','4','5','6','7','8','9']\n",
    "for i in range(65,91):\n",
    "    list.append(chr(i))\n",
    "for i in range(97,123):\n",
    "    list.append(chr(i))\n",
    "print(list)\n",
    "for c in contours:\n",
    "    x,y,w,h=cv2.boundingRect(c)\n",
    "    if w>5 and h>5:\n",
    "        \n",
    "        img4=cv2.rectangle(img3,(x,y),(x+w,y+h),(255,255,0),1)     \n",
    "        \n",
    "        i=img3[y:y+h,x:x+w]\n",
    "        i=cv2.resize(i,(50,50))\n",
    "        i=cv2.cvtColor(i,cv2.COLOR_BGR2GRAY)\n",
    "        i = i.astype(\"float\") / 255.0\n",
    "        \n",
    "        ima = img_to_array(i)\n",
    "        ima = np.expand_dims(ima, axis=0)\n",
    "        pred = classifier.predict(ima)[0]\n",
    "        #print(list[pred.argmax()],pred.max())\n",
    "        img5=cv2.putText(img4,list[pred.argmax()],(x,y+h+20), font, 0.8 ,(255,255,255),2,cv2.LINE_AA)   \n",
    "        p.append(list[pred.argmax()])\n",
    "'''for c in contours:\n",
    "    x,y,w,h=cv2.boundingRect(c)\n",
    "    if w>5 and h>5:\n",
    "        img5=cv2.putText(img4,list[pred.argmax()],(x,y+h-35), font, 0.5,(255,255,255),2,cv2.LINE_AA)        \n",
    "from PIL import Image, ImageTk \n",
    "#img5.show()'''\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img5)\n",
    "plt.savefig('TensorF.png')\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import subprocess\n",
    "\n",
    "def ocr(path):\n",
    "    temp = tempfile.NamedTemporaryFile(delete=False)\n",
    "\n",
    "    process = subprocess.Popen(['tesseract', path, temp.name], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    process.communicate()\n",
    "\n",
    "    with open(temp.name + '.txt', 'r') as handle:\n",
    "        contents = handle.read()\n",
    "\n",
    "    os.remove(temp.name + '.txt')\n",
    "    os.remove(temp.name)\n",
    "\n",
    "    return contents\n",
    "\n",
    "str = ocr('TensorFlowResult.png.png')\n",
    "print(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "\n",
    "im = Image.open(\"TensorFlowResult.png\") # the second one \n",
    "im = im.filter(ImageFilter.MedianFilter())\n",
    "enhancer = ImageEnhance.Contrast(im)\n",
    "im = enhancer.enhance(22)\n",
    "im = im.convert('1')\n",
    "im.save('test2.jpg')\n",
    "\n",
    "text = pytesseract.image_to_string(Image.open('test2.jpg'))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_uuid": "e078debe659f1ddfd1b2506dcc5fa58c6500a399",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1aa56997b8>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c706b4a269ca5724afe93bf4693ada53d36e1b1b"
   },
   "source": [
    "**We can see that it matches most of the words but sometimes give error in diiferentiation of capital and small letters.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b9dc8536974c70051aa9788fe283fe115468d210"
   },
   "source": [
    "                          - - - - - - - - - - - - -- - - - - - - - - END- - - - - - - - - - - - - - - -- - - - - - - - - - - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_uuid": "aa3ff6f0be68127e9bca0d77a38c27d742aa6206"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from keras.preprocessing.image import img_to_array\\nimport numpy as np \\nlist=[\\'s1\\',\\'s2\\']\\nimage = cv2.imread(\\'../input/picture/main-qimg-03de963368e748a6fb7e399772b09c48-c\\')\\nprint(type(image))\\n# pre-process the image for classification\\nimage = cv2.resize(image, (50,50))\\nima=image\\n\\nimage = image.astype(\"float\") / 255.0\\nimage = img_to_array(image)\\nimage = np.expand_dims(image, axis=0)\\nprint(image.shape)\\n\\npred = classifier.predict(image)[0]\\nfor i in range(2):\\n    if pred[i]>0.5:\\n        print(list[i],(pred[i]).astype(\\'float32\\'))\\n    \\n\\nprint(pred)\\n\\n#classifier.save(\\'../input/model.h5\\')'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from keras.preprocessing.image import img_to_array\n",
    "import numpy as np \n",
    "list=['s1','s2']\n",
    "image = cv2.imread('../input/picture/main-qimg-03de963368e748a6fb7e399772b09c48-c')\n",
    "print(type(image))\n",
    "# pre-process the image for classification\n",
    "image = cv2.resize(image, (50,50))\n",
    "ima=image\n",
    "\n",
    "image = image.astype(\"float\") / 255.0\n",
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "print(image.shape)\n",
    "\n",
    "pred = classifier.predict(image)[0]\n",
    "for i in range(2):\n",
    "    if pred[i]>0.5:\n",
    "        print(list[i],(pred[i]).astype('float32'))\n",
    "    \n",
    "\n",
    "print(pred)\n",
    "\n",
    "#classifier.save('../input/model.h5')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "_uuid": "2a84a101f81fe6287f3d24be1e185d08b79a1153"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import cv2\\nprint((ima.shape))\\n\\ngray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\\nface_cascade = cv2.CascadeClassifier('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/opencv-files/haarcascade_frontalface_alt.xml')\\nfaces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5)\\n(x,y,w,h)=faces[0]\\nimm=gray[y:y+w, x:x+h]\\nprint((gray.shape))\\nimport matplotlib.pyplot as mat\\nmat.plot(imm)\\ncv2.waitKey()\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import cv2\n",
    "print((ima.shape))\n",
    "\n",
    "gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "face_cascade = cv2.CascadeClassifier('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/opencv-files/haarcascade_frontalface_alt.xml')\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5)\n",
    "(x,y,w,h)=faces[0]\n",
    "imm=gray[y:y+w, x:x+h]\n",
    "print((gray.shape))\n",
    "import matplotlib.pyplot as mat\n",
    "mat.plot(imm)\n",
    "cv2.waitKey()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "_uuid": "60dfb948b939843aac837b4f348a7a75d4943510"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import cv2\\nf=[]\\nl=[]\\ndir=sorted(list(os.listdir('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/training-data')))\\nfor i in dir:\\n    s=sorted(list(os.listdir('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/training-data/'+i)))\\n    for j in s:\\n        print(i)\\n        k=cv2.imread('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/training-data/'+i+'/'+j)\\n        gray=cv2.cvtColor(k,cv2.COLOR_BGR2GRAY)\\n        face_cascade=cv2.CascadeClassifier('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/opencv-files/lbpcascade_frontalface.xml')\\n        faces=face_cascade.detectMultiScale(gray,1.2,9)\\n        if len(faces)>0:\\n            (x,y,w,h)=faces[0]\\n            face=gray[y:y+h,x:x+w]\\n            f.append(face)\\n            label=i\\n            if label=='s1':\\n                l.append(1)\\n            else:\\n                l.append(0)\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import cv2\n",
    "f=[]\n",
    "l=[]\n",
    "dir=sorted(list(os.listdir('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/training-data')))\n",
    "for i in dir:\n",
    "    s=sorted(list(os.listdir('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/training-data/'+i)))\n",
    "    for j in s:\n",
    "        print(i)\n",
    "        k=cv2.imread('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/training-data/'+i+'/'+j)\n",
    "        gray=cv2.cvtColor(k,cv2.COLOR_BGR2GRAY)\n",
    "        face_cascade=cv2.CascadeClassifier('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/opencv-files/lbpcascade_frontalface.xml')\n",
    "        faces=face_cascade.detectMultiScale(gray,1.2,9)\n",
    "        if len(faces)>0:\n",
    "            (x,y,w,h)=faces[0]\n",
    "            face=gray[y:y+h,x:x+w]\n",
    "            f.append(face)\n",
    "            label=i\n",
    "            if label=='s1':\n",
    "                l.append(1)\n",
    "            else:\n",
    "                l.append(0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d99d094ecb39942036eb451783589c96a9d189ae"
   },
   "outputs": [],
   "source": [
    "'''face_rec=cv2.face.LBPHFaceRecognizer_create()\n",
    "face_rec.train(f,np.array(l))\n",
    "testimg='../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/test-data/test1.jpg'\n",
    "lab,conf=face_rec.predict(testimg)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
