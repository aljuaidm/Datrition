{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_contours(cnts, method=\"left-to-right\"):\n",
    "    # initialize the reverse flag and sort index\n",
    "    reverse = False\n",
    "    i = 0\n",
    "\n",
    "    # handle if we need to sort in reverse\n",
    "    if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "        reverse = False\n",
    "\n",
    "    # handle if we are sorting against the y-coordinate rather than\n",
    "    # the x-coordinate of the bounding box\n",
    "    if method == \"top-to-bottom\" or method == \"right-to-left\":\n",
    "        i = 1\n",
    "\n",
    "    # construct the list of bounding boxes and sort them from top to\n",
    "    # bottom\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "        key=lambda b:b[1][i], reverse=reverse))\n",
    "\n",
    "    # return the list of sorted contours and bounding boxes\n",
    "    return (cnts, boundingBoxes)\n",
    "\n",
    "# Find contours for image, which will detect all the boxes\n",
    "# contours, hierarchy = cv2.findContours(img_final_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# # Sort all the contours by top to bottom.\n",
    "# (contours, boundingBoxes) = sort_contours(contours, method=\"top-to-bottom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(y):\n",
    "    # Defining a kernel length\n",
    "    global horizontal_lines_img, verticle_lines_img, kernel\n",
    "    kernel_length = np.array(img).shape[1]//y\n",
    "\n",
    "    # A verticle kernel of (1 X kernel_length), which will detect all the verticle lines from the image.\n",
    "    verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
    "    # A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.\n",
    "    hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "    # A kernel of (3 X 3) ones.\n",
    "    ###kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    # Morphological operation to detect vertical lines from an image\n",
    "    img_temp1 = cv2.erode(img_bin, verticle_kernel, iterations=1)\n",
    "    verticle_lines_img = cv2.dilate(img_temp1, verticle_kernel, iterations=1)\n",
    "    cv2.imwrite(\"verticle_lines.jpg\",verticle_lines_img)\n",
    "    # Morphological operation to detect horizontal lines from an image\n",
    "    img_temp2 = cv2.erode(img_bin, hori_kernel, iterations=1)\n",
    "    horizontal_lines_img = cv2.dilate(img_temp2, hori_kernel, iterations=1)\n",
    "    ###plt.subplot(1, 2, 1)  # 2 rows, 2 columns, 1st subplot = top left\n",
    "    ###plt.imshow(verticle_lines_img);\n",
    "    ###plt.axis('off')\n",
    "\n",
    "    ###plt.subplot(1, 2, 2)  # 2 rows, 2 columns, 2nd subplot = top right\n",
    "    plt.imshow(horizontal_lines_img);\n",
    "    plt.axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numbers of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "images = []\n",
    "for img_path in glob.glob('img/*.jpg'):\n",
    "    images.append(mpimg.imread(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The images are saved in the folder named as 'img_result'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 40/188 [03:27<27:46, 11.26s/it]"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "images = []\n",
    "counter = 1\n",
    "for img_path in tqdm(glob.glob('img/*.jpg')):\n",
    "    \n",
    "    img = cv2.imread(img_path,0)\n",
    "    (thresh, img_bin) = cv2.threshold(img, 240, 255,cv2.THRESH_BINARY|cv2.THRESH_OTSU)\n",
    "    img_bin = 255-img_bin\n",
    "    f(255)\n",
    "    alpha = 0.7\n",
    "    beta = 1.0 - alpha\n",
    "    # This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
    "    img_final_bin = cv2.addWeighted(verticle_lines_img, alpha, horizontal_lines_img, beta, 0.5)\n",
    "    #img_final_bin = cv2.erode(~img_final_bin, kernel, iterations=2)\n",
    "    (thresh, img_final_bin) = cv2.threshold(img_final_bin, 230,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img_final_bin)\n",
    "#     images.append(mpimg.imread(img_path))\n",
    "    # Find contours for image, which will detect all the boxes\n",
    "    contours, hierarchy = cv2.findContours(img_final_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Sort all the contours by top to bottom.\n",
    "    (contours, boundingBoxes) = sort_contours(contours, method=\"top-to-bottom\")\n",
    "    idx = 1\n",
    "    \n",
    "    for c in (contours):\n",
    "        # Returns the location and width,height for every contour\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "    # If the box height is greater then 20, widht is >80, then only save it as a box in \"cropped/\" folder.\n",
    "        if (w > 160 and h > 80) and w < 2.5 *h:\n",
    "            idx += 3\n",
    "            new_img = img[y:y+h, x:x+w]\n",
    "            #plt.subplot(2,3, idx)\n",
    "            plt.imshow(new_img)\n",
    "            plt.axis('off')\n",
    "            #cv2.imwrite('./th/')\n",
    "            #path = './th/'\n",
    "            plt.savefig(f'./img_result/label{counter}.jpg')\n",
    "            #cv2.imwrite(os.path.join(path , 'label'+str(num)+'.jpg'), new_img)\n",
    "            #cv2.imwrite(os.path.join(path , 'f', new_img))\n",
    "            counter+=1\n",
    "            #cv2.waitKey(0)\n",
    "    #break\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Extracting text from Nutrition lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance, ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "#import Image\n",
    "import pytesseract\n",
    "import re\n",
    "import sys\n",
    "\n",
    "sys.path.append('/usr/local/lib/python2.7/site-packages')\n",
    "import cv2\n",
    "\n",
    "def writeFile(directory, fileName, content):\n",
    "    outFile = open('outputs/' + directory + '/' + fileName + '.txt', 'w')\n",
    "    outFile.write(content)\n",
    "    outFile.close()\n",
    "\n",
    "# Setup regex for stripping file names\n",
    "p = re.compile('[0-9]+.jpg')\n",
    "    \n",
    "# Use images in the labels directory\n",
    "for file in glob.glob('../labels/*.jpg'):\n",
    "    fileName = p.findall(file)[0]\n",
    "    print (\"Proccessing \" + fileName)\n",
    "    outFileName = fileName[0:len(fileName)-4]\n",
    "    # Get default text recognition \n",
    "    output = pytesseract.image_to_string(Image.open(file))\n",
    "\n",
    "    # Write default text output to 'outputs/default' directory\n",
    "    writeFile('default', outFileName, output)\n",
    "\n",
    "    # Open image as black and white\n",
    "    bw = cv2.imread(file, 0)\n",
    "\n",
    "    # Apply adaptive thresholding to images\n",
    "    thresh = cv2.adaptiveThreshold(bw, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # Get text recognition from thresholded images\n",
    "    output = pytesseract.image_to_string(Image.fromarray(bw))\n",
    "    writeFile('bw', outFileName, output)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_Recognizer(path):\n",
    "    import re\n",
    "#    import end_to_end\n",
    "    import os\n",
    "    from matplotlib import pyplot \n",
    "    files = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for  r,d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            files.append(os.path.join(file))\n",
    "    p = re.compile('[0-9]+.jpg')\n",
    "    all_result = []\n",
    "    for f in files:\n",
    "        print(f)\n",
    "     #   out_dict = end_to_end.end_to_end(f'{path}\\{f}')\n",
    "        #-----------------\n",
    "        for file in glob.glob('./img_result/*.jpg'):\n",
    "            fileName = p.findall(file)[0]\n",
    "            print (\"Proccessing \" + fileName)\n",
    "            outFileName = fileName[0:len(fileName)-4]\n",
    "            # Get default text recognition \n",
    "            output = pytesseract.image_to_string(Image.open(file))\n",
    "\n",
    "            # Write default text output to 'outputs/default' directory\n",
    "            writeFile('default', outFileName, output)\n",
    "\n",
    "            # Open image as black and white\n",
    "            bw = cv2.imread(file, 0)\n",
    "\n",
    "            # Apply adaptive thresholding to images\n",
    "            thresh = cv2.adaptiveThreshold(bw, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "                    cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "            # Get text recognition from thresholded images\n",
    "            output = pytesseract.image_to_string(Image.fromarray(bw))\n",
    "                \n",
    "        \n",
    "        #-----------------\n",
    "#         print('This is out_dict type', type(out_dict))\n",
    "#         print(f.replace(r'.jpg',''))\n",
    "#         out_dict['Image_id']=f.replace(r'.jpg','')\n",
    "            all_result.append(output)\n",
    "            \n",
    "        break\n",
    "\n",
    "    df = pd.DataFrame(all_result)\n",
    "    df = pd.DataFrame(columns=['Image_id','Nutrient', 'Amount', 'Unit', 'Serving Size','Serving Size Unit','Language'])\n",
    "    df_long = df.melt(id_vars=['Serving Size','Image_id'])\n",
    "    Units = {'Calories': 'Kcal',\n",
    "        'Energy': 'kJ',\n",
    "        'Total Fat': 'g',\n",
    "        'Saturated Fat': 'g',\n",
    "        'Trans Fat': 'g',\n",
    "        'Poly Fat': 'g',\n",
    "        'Mono Fat': 'g',\n",
    "        'Cholesterol': 'mg',\n",
    "        'Sodium': 'mg',\n",
    "        'Potassium': 'g',\n",
    "        'Total Carbohydrate': 'g',\n",
    "        'Dietary Fiber': 'g',\n",
    "        'Sugars': 'g',\n",
    "        'Protein': 'g'}\n",
    "    df_long['Serving Size Unit']= 'g'\n",
    "    df_long.columns = ['Serving Size','Image_id','Nutrient','Amount','Serving Size Unit']\n",
    "    df_long['Unit'] = [Units [x] for x in df_long['Nutrient']]\n",
    "    df_long['Language'] = 'English'\n",
    "    Final_Outcome = df_long[['Image_id','Nutrient', 'Amount', 'Unit', 'Serving Size','Serving Size Unit','Language']]\n",
    "    Final_Outcome.to_excel('DSI-V-Abdulrahman.xlsx', index=False)\n",
    "    return Final_Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df['Image_id'] = ['Image_'+str(x) i for i in range(240) for _ in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label12.jpg\n",
      "Proccessing 12.jpg\n",
      "Proccessing 157.jpg\n",
      "Proccessing 143.jpg\n",
      "Proccessing 142.jpg\n",
      "Proccessing 156.jpg\n",
      "Proccessing 13.jpg\n",
      "Proccessing 9.jpg\n",
      "Proccessing 39.jpg\n",
      "Proccessing 11.jpg\n",
      "Proccessing 140.jpg\n",
      "Proccessing 154.jpg\n",
      "Proccessing 168.jpg\n",
      "Proccessing 155.jpg\n",
      "Proccessing 141.jpg\n",
      "Proccessing 10.jpg\n",
      "Proccessing 38.jpg\n",
      "Proccessing 8.jpg\n",
      "Proccessing 14.jpg\n",
      "Proccessing 28.jpg\n",
      "Proccessing 145.jpg\n",
      "Proccessing 151.jpg\n",
      "Proccessing 150.jpg\n",
      "Proccessing 144.jpg\n",
      "Proccessing 29.jpg\n",
      "Proccessing 15.jpg\n",
      "Proccessing 17.jpg\n",
      "Proccessing 152.jpg\n",
      "Proccessing 146.jpg\n",
      "Proccessing 147.jpg\n",
      "Proccessing 153.jpg\n",
      "Proccessing 16.jpg\n",
      "Proccessing 59.jpg\n",
      "Proccessing 71.jpg\n",
      "Proccessing 65.jpg\n",
      "Proccessing 134.jpg\n",
      "Proccessing 120.jpg\n",
      "Proccessing 108.jpg\n",
      "Proccessing 109.jpg\n",
      "Proccessing 121.jpg\n",
      "Proccessing 135.jpg\n",
      "Proccessing 64.jpg\n",
      "Proccessing 70.jpg\n",
      "Proccessing 58.jpg\n",
      "Proccessing 66.jpg\n",
      "Proccessing 72.jpg\n",
      "Proccessing 99.jpg\n",
      "Proccessing 123.jpg\n",
      "Proccessing 137.jpg\n",
      "Proccessing 136.jpg\n",
      "Proccessing 122.jpg\n",
      "Proccessing 98.jpg\n",
      "Proccessing 73.jpg\n",
      "Proccessing 67.jpg\n",
      "Proccessing 63.jpg\n",
      "Proccessing 77.jpg\n",
      "Proccessing 88.jpg\n",
      "Proccessing 126.jpg\n",
      "Proccessing 132.jpg\n",
      "Proccessing 133.jpg\n",
      "Proccessing 127.jpg\n",
      "Proccessing 89.jpg\n",
      "Proccessing 76.jpg\n",
      "Proccessing 62.jpg\n",
      "Proccessing 74.jpg\n",
      "Proccessing 60.jpg\n",
      "Proccessing 48.jpg\n",
      "Proccessing 119.jpg\n",
      "Proccessing 131.jpg\n",
      "Proccessing 125.jpg\n",
      "Proccessing 124.jpg\n",
      "Proccessing 130.jpg\n",
      "Proccessing 118.jpg\n",
      "Proccessing 49.jpg\n",
      "Proccessing 61.jpg\n",
      "Proccessing 75.jpg\n",
      "Proccessing 78.jpg\n",
      "Proccessing 50.jpg\n",
      "Proccessing 44.jpg\n",
      "Proccessing 93.jpg\n",
      "Proccessing 87.jpg\n",
      "Proccessing 115.jpg\n",
      "Proccessing 101.jpg\n",
      "Proccessing 129.jpg\n",
      "Proccessing 128.jpg\n",
      "Proccessing 100.jpg\n",
      "Proccessing 114.jpg\n",
      "Proccessing 86.jpg\n",
      "Proccessing 92.jpg\n",
      "Proccessing 45.jpg\n",
      "Proccessing 51.jpg\n",
      "Proccessing 79.jpg\n",
      "Proccessing 47.jpg\n",
      "Proccessing 53.jpg\n",
      "Proccessing 84.jpg\n",
      "Proccessing 90.jpg\n",
      "Proccessing 102.jpg\n",
      "Proccessing 116.jpg\n",
      "Proccessing 117.jpg\n",
      "Proccessing 103.jpg\n",
      "Proccessing 91.jpg\n",
      "Proccessing 85.jpg\n",
      "Proccessing 52.jpg\n",
      "Proccessing 46.jpg\n",
      "Proccessing 42.jpg\n",
      "Proccessing 56.jpg\n",
      "Proccessing 81.jpg\n",
      "Proccessing 95.jpg\n",
      "Proccessing 107.jpg\n",
      "Proccessing 113.jpg\n",
      "Proccessing 112.jpg\n",
      "Proccessing 106.jpg\n",
      "Proccessing 94.jpg\n",
      "Proccessing 80.jpg\n",
      "Proccessing 57.jpg\n",
      "Proccessing 43.jpg\n",
      "Proccessing 55.jpg\n",
      "Proccessing 41.jpg\n",
      "Proccessing 69.jpg\n",
      "Proccessing 96.jpg\n",
      "Proccessing 82.jpg\n",
      "Proccessing 138.jpg\n",
      "Proccessing 110.jpg\n",
      "Proccessing 104.jpg\n",
      "Proccessing 105.jpg\n",
      "Proccessing 111.jpg\n",
      "Proccessing 139.jpg\n",
      "Proccessing 83.jpg\n",
      "Proccessing 97.jpg\n",
      "Proccessing 68.jpg\n",
      "Proccessing 40.jpg\n",
      "Proccessing 54.jpg\n",
      "Proccessing 3.jpg\n",
      "Proccessing 33.jpg\n",
      "Proccessing 27.jpg\n",
      "Proccessing 162.jpg\n",
      "Proccessing 163.jpg\n",
      "Proccessing 26.jpg\n",
      "Proccessing 32.jpg\n",
      "Proccessing 2.jpg\n",
      "Proccessing 18.jpg\n",
      "Proccessing 24.jpg\n",
      "Proccessing 30.jpg\n",
      "Proccessing 161.jpg\n",
      "Proccessing 149.jpg\n",
      "Proccessing 148.jpg\n",
      "Proccessing 160.jpg\n",
      "Proccessing 31.jpg\n",
      "Proccessing 25.jpg\n",
      "Proccessing 19.jpg\n",
      "Proccessing 1.jpg\n",
      "Proccessing 5.jpg\n",
      "Proccessing 21.jpg\n",
      "Proccessing 35.jpg\n",
      "Proccessing 158.jpg\n",
      "Proccessing 164.jpg\n",
      "Proccessing 165.jpg\n",
      "Proccessing 159.jpg\n",
      "Proccessing 34.jpg\n",
      "Proccessing 20.jpg\n",
      "Proccessing 4.jpg\n",
      "Proccessing 6.jpg\n",
      "Proccessing 36.jpg\n",
      "Proccessing 22.jpg\n",
      "Proccessing 167.jpg\n",
      "Proccessing 166.jpg\n",
      "Proccessing 23.jpg\n",
      "Proccessing 37.jpg\n",
      "Proccessing 7.jpg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_id</th>\n",
       "      <th>Nutrient</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Serving Size</th>\n",
       "      <th>Serving Size Unit</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Image_id, Nutrient, Amount, Unit, Serving Size, Serving Size Unit, Language]\n",
       "Index: []"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_Recognizer('img_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basename = os.path.basename(impath)\n",
    "    label_impath = impath.replace(basename, 'tmp_' + basename)\n",
    "    # label_impath = impath.lower().replace('.jpg', 'label_tmp.jpg')\n",
    "    cv2.imwrite(label_impath, label_im)\n",
    "\n",
    "    start = timer()\n",
    "    # Apply Tesseract to image\n",
    "    output = apply_tesseract(label_impath, demo=demo)\n",
    "#        print (\"\\n\")\n",
    "    output = pytesseract.image_to_string(label_impath,lang='eng')\n",
    "#     print(arabic)\n",
    "\n",
    "    end = timer()\n",
    "    print('OCR time: %2f' % (end-start))\n",
    "    os.remove(label_impath)\n",
    "\n",
    "    start = timer()\n",
    "    ocr_label = post_process(output, demo=demo)\n",
    "    print(ocr_label)\n",
    "\n",
    "    end = timer()\n",
    "    print('Post process time: %2f' % (end-start))\n",
    "\n",
    "    if show:\n",
    "        draw_image(label_im, 'Transformed label: %s' % impath)\n",
    "\n",
    "    return ocr_label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
