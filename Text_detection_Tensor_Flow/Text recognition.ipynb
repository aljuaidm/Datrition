{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'jpg']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"./images_sample/\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D,BatchNormalization\n",
    "from keras.layers import MaxPooling2D,Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0fb507b8d05f98844507569ba23f846a5929403c"
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "ed7dfb86d7e42bfb12104c6a0f261e90f202c262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 50, 50, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 25, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 25, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 62)                31806     \n",
      "=================================================================\n",
      "Total params: 2,670,846\n",
      "Trainable params: 2,669,822\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/Datrition/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=62)`\n"
     ]
    }
   ],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape = (50, 50,1), activation = 'relu',padding='same'))\n",
    "# Adding a second convolutional layer\n",
    "#classifier.add(BatchNormalization(axis=1))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "classifier.add(Convolution2D(64, (3, 3), activation = 'relu',padding='same'))\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Convolution2D(64, (3, 3), activation = 'relu',padding='same'))\n",
    "#classifier.add(BatchNormalization(axis=1))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "classifier.add(Convolution2D(128, (3, 3), activation = 'relu',padding='same'))\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Convolution2D(128, (3, 3), activation = 'relu',padding='same'))\n",
    "#classifier.add(BatchNormalization(axis=1))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(512,activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(0.5))\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(output_dim = 62, activation = 'softmax'))\n",
    "\n",
    "# Compiling the CNN\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "classifier.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5ffdc6c72c61e3a9b0d3597428c0b7496e8810eb"
   },
   "source": [
    "# Fitting Image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "0b4685510213dfbfeab1428518542e1af57e9e47",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 436 images belonging to 1 classes.\n",
      "Epoch 1/5\n",
      "40/40 [==============================] - 121s 3s/step - loss: 3.4142 - accuracy: 0.7110\n",
      "Epoch 2/5\n",
      "40/40 [==============================] - 118s 3s/step - loss: 0.7071 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "40/40 [==============================] - 119s 3s/step - loss: 0.0317 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "40/40 [==============================] - 118s 3s/step - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "40/40 [==============================] - 116s 3s/step - loss: 0.0092 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a5fb88c18>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   shear_range=0.2,\n",
    "\n",
    "                                  )\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('./images_sample/',\n",
    "                                                target_size = (50,50),\n",
    "                                               batch_size = 128,\n",
    "                                                 color_mode= \"grayscale\",\n",
    "                                              class_mode = 'categorical')\n",
    "\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                         epochs = 5,\n",
    "                         steps_per_epoch=40,\n",
    "                         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1e340fdf04229c9ee15d2f7d51a9de028dcf8277"
   },
   "source": [
    "# Preprocessing the text doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "114ed7cc742a0c59bedcbe8ceca62d7fec8aa4ce",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAdCElEQVR4nO2dW6wcR5nHfx82zgqTgA9ZRxPH2hhiHiIZBa8dEnFREgkn8UvgYZUL2lgB+SCEcXjgwSxCyStI8BCEItsi2rBiEyEBioWWta1cxAMh2FkFOyZrfJwx+MQndpCthGiV+JJvH6Z6TndP90z3TF+qp7+f1Jqemuqur3vqX1/dulpUFcMw2sX76jbAMIzqMeEbRgsx4RtGCzHhG0YLMeEbRgsx4RtGC6lc+CJyh4gcFZE5EdlRdfqGYYBUOY4vIkuAPwOfB+aBA8C9qvqnyowwDKNyj38jMKeqr6rqeeBJ4K6KbTCM1rO04vRWASdD3+eBT4UjiMgsMOu+/nNFdhnGNPI3Vf3HpB+qFr4khEXaGqq6C9gFICI2n9gwxucvaT9UXdWfB1aHvl8DnKrYBsNoPVUL/wCwVkTWiMgy4B5gT8U2GEbrqbSqr6oXRWQbsBdYAjymqkeqtMEwjIqH8/JibXzDmIgXVXVD0g82c88wWogJ3zBaiAnfMFqICd8wWogJ3zBaiAnfMFqICd8wWogJ3zBaiAnfMFqICd8wWogJ3zBaiAnfMFqICd8wWogJ3zBaiAnfyI3HT3I3ixpvpAnfMFqICd8wWogJ3zBaiAnfMFqICd8wWogJ3zBaiAm/Cdj4WWaGrRqd9pvPK02XhQm/ASRlyzZmVhguXlVFRFLji0hr71scE74HhDNjUsZMyrDxDD6tZL1uEUn8LR7W5nsZxoTvAUFmDDxWmvhhUAjT7sGyijKp8Ey7N+H7nXaOaceEXxYZM1GQ2QKPlVRdjccL00ZvlUT4PgT7o+5Nm++lCb8sgkyU4lXyCjk1U7bISyUxrpduk8iTMOGXTYqwh3VCoZpd0C3PwMME3Oaq/CgqfVuukU4kA7dczEXR5qr8KMzjl4R5F8Nn2i38EsXZKu9ihVzjaLfw2yTOMrH7OB413rd2C38YbfViRV93W++j50wkfBE5ISKHReQlETnowmZEZL+IHHOfK1y4iMgjIjInIodEZH0RF1Aa8dK4LRm4aC9ktQEvKcLj36qqN6jqBvd9B/C0qq4FnnbfAe4E1rptFni0gLSrYxoysEeFV5M7P5tse0AZVf27gMfd/uPAF0LhP9Uevwc+LCKdEtKvn7ozRlr6HhVeWTo/6xbYsCm/TWdS4SuwT0ReFJFZF3aVqi4AuM+VLnwVcDJ07LwLiyAisyJyMGg6NJK6M0bd6RdE3QKrO/0ymXQCz6dV9ZSIrAT2i8j/DombdBcHilRV3QXsAhCR5tepfEV1agqIOkl7tsJ3JvL4qnrKfZ4BfgXcCJwOqvDu84yLPg+sDh1+DXBqkvSNCWhgZh2XMpsMTRQ9TCB8EVkuIpcH+8Am4GVgD7DFRdsCPOX29wD3u979m4A3gyaB0aOyNm08nUnSndDmKq65qeIsk0mq+lcBv3I3dSnwn6r63yJyAPi5iHwF+CvwLy7+fwGbgTng/4AHJkh7Kqksg8bTERm/6h9+CnGM41styhqbW1J3z+kwrI1fAxkyo6/dA161t7PcpPJv5IuhYfYINnOvSVRRJa9ROJM6IW9ED36WjCFM+E0iZXGPXMd6jFfCnXLseXyPSde3JC+9mxPTWXsxjz8GnU5VEw4VEUrbjPZiwh+DhYVqRiGt6muUhQnfMFqICb/peDwca/iLCb/pWHPAGAPr1TcazahJO8PeStRmTPhGo8n7thyjh1X1pwlr7xsZMeFXQVWCbIF38/nZkiZhwq+CFgiyKqzqXgwmfMNoISZ8w2ghJnzDaCEmfMNoISZ8Y+qwnv/RmPANg/YVFiZ8ozG0TZxlYsI3BjGBTT0m/GmjCNG2cJJM2yYGmfCnjZZl4DjWHMiGCd9IxkMBZfHK43juMgsLXwsiE76RTINrDkVV24sQra9NCBP+lOOrxwlTt42+irNMTPhF4anA8mTqugRYt/DSrrtuu8rEhF8UU5BJpjmjG1FM+EXgqbcfoCl2VkwRBV7dzZW8mPCLoCmesil2esy0NAtM+IaRg6YJPA0TfgK5343XsGpek2haFbopmPCLYJLXVxveEi90pqkQGil8EXlMRM6IyMuhsBkR2S8ix9znChcuIvKIiMyJyCERWR86ZouLf0xEtpRzOcUw9ksxw9XAujNJ3ekXRJ1V63ja01LNh2we/9+BO2JhO4CnVXUt8LT7DnAnsNZts8Cj0CsogIeATwE3Ag8FhcXUUncmqTt9w2tGCl9VfwucjQXfBTzu9h8HvhAK/6n2+D3wYRHpALcD+1X1rKqeA/YzWJhMH1PidY3pY9xXaF2lqgsAqrogIitd+CrgZCjevAtLCx9ARGbp1Raaj3ldw1OKfndeUk7XIeGDgaq7gF0AImIu0zBKYNxe/dOuCo/7POPC54HVoXjXAKeGhBtGoUxTz3uZjCv8PUDQM78FeCoUfr/r3b8JeNM1CfYCm0RkhevU2+TCDMOoA1UdugFPAAvABXqe+yvAR+j15h9znzMurgA/Bo4Dh4ENofN8GZhz2wOj0nXHqG3+bapZ4mhNttWT7lhb+bYeTNOW+Fw1sja+n6hm77dU1UrHv6tObyLy3MjxeFFVNyT9YDP3htDtdus2ofFMKsK8jqkxoq8ZE/4Q1q5dW7cJrceEXA4m/CFcvHixbhMMoxRM+NOKx303Rv2Y8KcVqyIbQzDhl4V5XMNjTPhlYR7X8BgTvmG0EBO+kY41VyKMO9nNx0lyJnwjHWuuFIKPcxFM+MYAPnooo1hM+MYA586dq9sEL/HRc4+LCd8YYGZmpm4TAKt5lIkJ3zBaSNFLbxm+kPDI5zAH6mMttmlV6yY9EmzCn1YSMmBD8mRjCIQefDZF9GBVff8Yt107SXvY2tIDZOlfCITeJMEHmPB9Y9xMlHZcOAOnZeYGZtyyCcQ8rR2MJnzfmTTjmaiBfAIOx22iN8+CCb8ASl2iK57xJikIRKa2Wj9K2HkEHI8bnHuavL8JP2CCP7XSJbqSMnCC7amZdEo9WJpY8xJa4Xng3NPk/U34ARP8qbUv0ZVQK5imTDoO47bRm9Y7Py4mfB8ougrZgoyblWC4rQisqt9CVBc3YzKqFlBRHnyaagIm/IyILG6lnDyJrAJpWGlUpBeeFF/sqBoTvs9kKBA6nU4jq/a+eM+sdkxbAWHCz0tKBig8Y4TOF25mqIIi/Z/feOONYtOtgfi9S7qXda5+06Q5+Fkx4eclJQMUnjFC55ud3RppaoSbHLWPKBRA/N4VeS+LGOZLsqfpNQB7aWaNDPMkwd/io6Mp/12P/hLopZDCyV6aOaWMKFRnZ2dT4xfWkehxwZ6Gz84I/OmfmATz+D5ThEcowatMcsoi28tltb0ra9Obx58udu7cWcyJisgUDfBOdTuf+Fz8afDoozCPn5WE0nnjxo0cOHCgkHOVTbGethHlif/47PFF5DEROSMiL4fCHhaR10TkJbdtDv32bRGZE5GjInJ7KPwOFzYnIjsmvaLKSfiD5ufnazBkPPqi97igH5dhzivLUGH8N5+dYWEETyOlbcDngPXAy6Gwh4FvJcS9HvgjcBmwBjgOLHHbceCjwDIX5/oMaasv29atWwfCtGdkQnj99pa5+XZ9af/DpHFL38q35WCatkZ6fFX9LXB2VDzHXcCTqvquqnaBOeBGt82p6quqeh540sVtDLt37x4Im7jqnMezjIrbBi+VQpb/Id5+b4VXH8IknXvbROSQawqscGGrgJOhOPMuLC18ABGZFZGDInJwAtuqoczVcXLMENy3b1+jG91ViLDMSUJNZFzhPwp8DLgBWAB+4MKT7qYOCR8MVN2lqhvSOiUaQ1GFQmwmT9KN3LRp02Rp1cwwEbbdM5fFWMtrq+rpYF9EdgO/dl/ngdWhqNcAp9x+WnhzGeY1mjGzy3va7pnLYiyPLyKd0NcvAkGP/x7gHhG5TETWAGuBPwAHgLUiskZElgH3uLiGI/4gDpAs+pYKwTx/sYz0+CLyBHALcKWIzAMPAbeIyA30qusngK8CqOoREfk58CfgIvB1Vb3kzrMN2Euvh/8xVT1S+NU0hHgeFoETJ7qsWbMm8zHhY9uAef5isQk8JTDtNfQqrm8aH4UdwOcJPMZ4XHHFFXWb0Gh8WqVnGjHhJ1FAhnvrrbcKMKRdpC1rHYtUkTXTjQk/iYzVr6VLk7tIMtfegkxsmRnIOK140vUJDcCEPxEXL1yY7ARBJp72tmxexrkfnr8lyLdmiwl/EsbJoJ5lgNKo4zo9LkB966g04RdF1ozuWQYojbZcZ0Mx4RdFHRm9LbUHo3BM+FmoSmB506mysCnhHkRmKVaUtldlZY21IhN+Fqr6g3wavkqaXljAqaLvngdJeFZL4yVCvONu6GIaqQnnMXnqMeFnpa6MU5dXKDDd5557dvG0GdJ57rnnBsND39d94hOpaYnAunXrBs/df9V1Fosros7CaNQqOHVu1L1Cim2JW94VeMKr3rzzzjup8YJVjoL4aavldLvdocen/R4/X97zT7zF06txBR6bqx9n2ifaZ2HEPRj3FgXH9Y8PBWi/LqBuum702Eh6kfi95oLG6hL98w8cTOjci88DDKRH7CKdrZFrD38Z56bYXH2jduJt6lLOrdHTh0qBxVeDRQUtAg8+uD16viC++z1yPLHrSLiWpLSi4TiRx86lGj1dQlOiKZjw40zxarRDCWXcomuB8bN1u93EdMNpB+IDeOSRRyK/dbvd3kNQCQ/yXHrvvf4pO50OSfSPcZ/qBN3pdPoPV8WfDtS+x9eB88zPzzdqxWUYcwWeqSVc9WpYCV4kwZNxRc82K/J8aQ9BLVmyJPtJnD3hV5kF5x14vVni4b3jL0w6dbsGrI2fhLXzh5L39sTjqyZUyV2PYdqbaaPeN+ffM7LPoqZn/62N7xkmeqD4Kv9AP0KsDS5JD9pkEeWomUApx8eX3G4TJvwq8bh2FadIL/jXv/6l164X4e6773YOfrDbXmMeMKldvW3btv7xd999dy/sG9/oH7ds2bLFYx1BW3/r1q2Rz6uvvjryvT/+3wbqHquf6nH88sdpS93CRMPzn+fmm2+OhJ09ezYxXvj7j370o8TwtLC039etW6eAPvHEEwroBz7wAQV06dKlkfBut5uaHRuaP2wcvzKKbrdVND4cr/YO8/hDT9/g/hHV0GyA+DUkXVdMO4r0x/9791OG34oa2/jWq180Rf+R4y5KkfuQ+Jj2mNfRWNEDSMKcYkdSp2PSpCFk8VweY238NDyuCWWiQPtrqRUmpZnBjnFNvfrqzsCzQKNPqkl9lIlhvmHCTyNLT3JVjJNWgRORaun1zmv/GNfZP0SVhYWFSLKRSCnXP+q+pE0g8gET/rj4XJyHaYqdMYJaRkTOIunLloeevkuaXZfEe+9d4tKlS4kzABPTz2E3wJVXXpnz6OqwNn4TKFC8iVNRqdCrp3jQuB3BzLm4XcHMuoTRwET6cwMSOuaWZOjAS3pgCEITkGIzk8IrBR/2uNA1j98y4i+qEJEBcZXSph8xySZux+7du1Pjnj9/PtKOjutroBBLEmCSwBPOcfr06f7DQJG0Ql+effbZwXN6LHow4U8POcQ6yruX4v2dULbOzvYnzORh27Zt/f33vS8523a73ZQ+Qe3/nnRMwLlz51Ddjuqyfjm1cuXKhEIias8tt9zS39+5c2em66kbG8f3mTzjvBWOn5eSVHDSDCfvqrImYe5+4px+NOTJLwDLeqd3B9188808//zz2WzLdTkZpxrbXH0jc8N14mQ0sTqfFp7G66+/Xog9ly5dQt34t7LYpv7sZz+b2EJYk3BfgrHz8JRdkWCsvbeJLOuXLUE6v/vd86Hjk+nbptEWS5Jti2FW1W8eddWCJhF6jmPD7em40PNU87/73e9mjjuMJUuWJLbZ5+bmIt8DUcfp/d4T+vnz512Y6+UPtc+HceJEr8qf1ByI2MbiYhzSKxIica++utO3xePK9GIp7+NGufOYq90aPm8/vGlZc9dHbNu3b89n22JGSo2bdC179+6NfJ+fnx/rvoy8TzXO1TePXxXjzLc3IgQr8QTEayv79u2Ljq4x6Oo3btzY30+qCXQ6HT7+8Y9HwoKFNjZu3Di0KdRvRqj/f5917k0zJXUeVdiPGE0TdZNtwp12oQdhRhmmSgdYGNKJqLqOCxdeTGxWdDodTp06lTi2vzh8vxWR3dnukc+deyKyWkSeFZFXROSIiDzowmdEZL+IHHOfK1y4iMgjIjInIodEZH3oXFtc/GMisqWoq5sIjwu+ifF8LDkT4f/HCVakt9/rqwjFGzXNV6Qn+uBcDNYaRA5HRR9y3wsLC8O77FSB3eHT+0uGdnYHWO/2Lwf+DFwPfB/Y4cJ3AN9z+5uB39Dr1rwJeMGFzwCvus8Vbn9FLW38KWpvj7vpBPdgoB1dop3Lli2L2Bz+nud64uv5dzodBXTfvn2R7/Gt2+265/RHX2fu9fhrbOOP0+H2FPB54CjQCRUOR93+TuDeUPyj7vd7gZ2h8Ei8qe/cm6Ktrs69YeLLWpAFtnc6nYjwegzGv1l7i4icjWbMxO21117Ld39qFH6uufoici3wSeAF4CpVXaB3pQsistJFWwWcDB0278LSwuNpzAKjlzitijoatEYiw4Yasw5DBtEWFhb6XzqdDrfddhvPPDMY/3kXZybD+VetWhVJw2cy9+qLyAeBXwDfVNXktY1d1IQwHRIeDVDdpaob0jolKqcJ/2LANPdXTEDS2DwsPjZ76tQCzzxzHcDYPfJN6MkPk0n4IvJ+eqL/mar+0gWfFpGO+70DnHHh88Dq0OHXAKeGhBujiOeoIZ1XTSRyOSWoJ/DE4TRUlTfeeAMIhvV2pz700ztEI8fHCSb3NIUsvfoC/AR4RVV/GPppD7DF7W+h1/YPwu93vfs3AW+6JsFeYJOIrHAjAJtcmH/4VnRnedrM4ePw7L59+wbCzp8/37c1fDndEycKT7/fSx/cGzcicPHixeEHhgblI02J9GeA2bvXzyw9QIbOvM/Qq5IfAl5y22bgI8DTwDH3OePiC/Bj4DhwGNgQOteXgTm3PZAh7Vo6kRI3Gwnob0V07vV7yoP76j5Le1PtkC14y26SjUnhSSMA8VGCTFuTevWr3OrO4BX9OY3b8go/3OOedGw/LCFeIQVB7D9UjYYFy2vHRwaC5bfDx/WPjcWNFwaZRhlqFL7N3DNyU8VAR5BGpsdmM5xMCS9CkrLsdezCVAcf84XkR4CHnWeYXd7O3DOMogiczGBfpQ4sTBnoYRLRDzg1Vd59912EXnrnQ7+rgrKf+0I2fulLX4raROjJPBFU3wl3A6DaWyugCZ2srfb4/VLb/VlB6yKYi13o/9eQDJGFvJeiugx4C/gHYPDYod5zAlTdyvcy+PbfTqfTX1l3MX501m9kOnCS4Wlp+rN4inn8JAKBK4tzwL/2ta/1942iOE8g+qq54kMfAohV2XVA9L04i/snTnQX33mfMManqtx6660JKUYX7fCVVgsfQv+p+2MfffTRYkvhHN5iWklaZKMqglV5wwQr+A5j1apVI997f9111w2E1Xmtuai7577OXv1w7+7x48dVVaNDO7706CfZMaZtARPftxzxt2/frvfdd99Qm2q/x778r8VuNpyXloGDbevWrYsZ0LeM6Jk9eYU/Kn6dwg8X/uH9Sv6PGoVvnXux+tjbb7/N8uXLh3fQlN8pU296I8hrjupiJ9s4v5eJ6uACHyPtKOr/KP9/tc69JJLEvXz58t5rlYYfWJJFnqRXMA8++OCie12szYELAwZ+T6kBGgXRauEnMTs7y8mTJ0dHrBCfX76YhfhaebAo8rSaVbAScHgziqPVVf1EslS/wnE8q4ZXwVhV/YSx9Ky/l4lV9Y0eo9r28TgtE/049Ne4H+Ldh/1uFI8JPw91ZcxwrczjGprRHEz4TcD3Gsa4hVHsuJGnsUKvMEz44GeG8tGmNMYtjPJ1FPhZ6DWUdgs/qc3uCz7aFGOc113Hydy5PGrN/DHTPn369f5Q4okT3cT7Hl5nvz8bSZXXX389MtQYfHZUU9f584V2C78B4vKZ2267LVf8uMjDvfnD4kWY9D8Lzu0mDT300EOLnYrXXhuN4whexOkM6A8vPnTVVc6khM7J4Fy+Uve03Dqn7No23pZrym6OaamZzjvBNNcrrrgilp4mfgYvyex0OgOr8MDiyzvTjs88BbnGKbvt9vhG+eRYGFQk/VXY/WbFBB4//qRe2lN64afykhbkDCYkBR4+y9N+vmETeIzcFNXPdvbsWWZmZvwxqGpsAo/RRCbt3CtE9NBM0deMeXwjN7U72NoNKAjz+O3E50LXa6ZB9DVjwq+LGh5IMYwAE37ZpHl1E71RIyb8MpmWtqgxdZjwy8REXyzWJ1IYS+s2oA4s/zQUV5DWsWDHtNFK4VueaQ7dbpc1a9bUbUY51JgRrapvNA7z9pNjwje8Zmq9fc2Y8A2jhZjwDaOFjBS+iKwWkWdF5BUROSIiD7rwh0XkNRF5yW2bQ8d8W0TmROSoiNweCr/Dhc2JyI5yLskwjJFkWAyjA6x3+5cDfwauBx4GvpUQ/3rgj8BlwBrgOLDEbceBjwLLXJzrbSEO22wrbUtdiGPkcJ6qLgALbv/vIvIKsGrIIXcBT6rqu0BXROaAG91vc6r6KoCIPOni/mmUDYZhFEuuNr6IXAt8EnjBBW0TkUMi8piIrHBhq4DwO6jmXVhaeDyNWRE5KCIH89hmGEZ2MgtfRD4I/AL4pqq+BTwKfAy4gV6N4AdB1ITDdUh4NEB1l6puSHuO2DCMyck0c09E3k9P9D9T1V8CqOrp0O+7gV+7r/PA6tDh1wCn3H5auGEYFZKlV1+AnwCvqOoPQ+HhV7h+EXjZ7e8B7hGRy0RkDbAW+ANwAFgrImtEZBlwj4trGEbFZPH4nwb+FTgsIi+5sH8D7hWRG+hV108AXwVQ1SMi8nN6nXYXga+r6iUAEdkG7KXXw/+Yqh4p8FoMw8iIrblnGNOLrblnGMYiJnzDaCG+P4//NnC0biMycCXwt7qNyIDZWSy+2/lPaT/4LvyjTRjPF5GDZmdxmJ3lY1V9w2ghJnzDaCG+C39X3QZkxOwsFrOzZLwexzcMoxx89/iGYZSACd8wWoi3wvdtmS4ROSEih90yYwdd2IyI7BeRY+5zhQsXEXnE2X5IRNaXaNdjInJGRF4OheW2S0S2uPjHRGRLRXZ6tXzbkGXmvLufEzNq6a06NsZYpqsCm04AV8bCvg/scPs7gO+5/c3Ab+itQXAT8EKJdn0OWA+8PK5dwAzwqvtc4fZXVGDnw5S8fFtOG9OWmfPufk66+erxb8Qt06Wq54FgmS7fuAt43O0/DnwhFP5T7fF74MOxx5gLQ1V/C5yd0K7bgf2qelZVzwH7gTsqsDON/vJtqtoFguXbSs0Xqrqgqv/j9v8OBMvMeXc/J8VX4WdapqtiFNgnIi+KyKwLu0p7axLiPle68Lrtz2tXnfYWvnxbEcSWmWvS/cyEr8LPtExXxXxaVdcDdwJfF5HPDYnro/0w4bJoJVDK8m2TkrDMXGrUFHt8/f/7+Cr8Yct31YKqnnKfZ4Bf0at2ng6q8O7zjItet/157arFXlU9raqXVPU9YDeLqzHXZmfSMnM05H7mwVfhe7VMl4gsF5HLg31gE72lxvYAQY/tFuApt78HuN/1+t4EvBlUFSsir117gU0issJVtze5sFIRz5ZvE0leZo6G3M9c1N27OKSHdTO9XtXjwHdqtuWj9HqQ/wgcCewBPgI8DRxznzMuXIAfO9sPAxtKtO0JetXkC/Q8zVfGsQv4Mr1OtDnggYrs/A9nxyF6IuqE4n/H2XkUuLOKfAF8hl6V/BDwkts2+3g/J91syq5htBBfq/qGYZSICd8wWogJ3zBaiAnfMFqICd8wWogJ3zBaiAnfMFrI/wPE0C128k8IXwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "img=cv2.imread('../Box_detection_2/images/764216_bag.jpg')\n",
    "imagee=img.copy()\n",
    "img=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "ret,img=cv2.threshold(img,180,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "k=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "\n",
    "img = cv2.morphologyEx(img, cv2.MORPH_OPEN, k)\n",
    "k1=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(1,1))\n",
    "img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, k)\n",
    "\n",
    "img1=cv2.Canny(img,0,255,2)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(img1,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "img2=cv2.cvtColor(img1,cv2.COLOR_GRAY2BGR)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "img3=cv2.drawContours(img2, contours, -1, (0,255,255), 1)\n",
    "image=[]\n",
    "p=[]\n",
    "list=['0','1','2','3','4','5','6','7','8','9']\n",
    "for i in range(65,91):\n",
    "    list.append(chr(i))\n",
    "for i in range(97,123):\n",
    "    list.append(chr(i))\n",
    "print(list)\n",
    "for c in contours:\n",
    "    x,y,w,h=cv2.boundingRect(c)\n",
    "    if w>5 and h>5:\n",
    "        \n",
    "        img4=cv2.rectangle(img3,(x,y),(x+w,y+h),(255,255,0),1)     \n",
    "        \n",
    "        i=img3[y:y+h,x:x+w]\n",
    "        i=cv2.resize(i,(50,50))\n",
    "        i=cv2.cvtColor(i,cv2.COLOR_BGR2GRAY)\n",
    "        i = i.astype(\"float\") / 255.0\n",
    "        \n",
    "        ima = img_to_array(i)\n",
    "        ima = np.expand_dims(ima, axis=0)\n",
    "        pred = classifier.predict(ima)[0]\n",
    "        #print(list[pred.argmax()],pred.max())\n",
    "        img5=cv2.putText(img4,list[pred.argmax()],(x,y+h+20), font, 0.8 ,(255,255,255),2,cv2.LINE_AA)   \n",
    "        p.append(list[pred.argmax()])\n",
    "'''for c in contours:\n",
    "    x,y,w,h=cv2.boundingRect(c)\n",
    "    if w>5 and h>5:\n",
    "        img5=cv2.putText(img4,list[pred.argmax()],(x,y+h-35), font, 0.5,(255,255,255),2,cv2.LINE_AA)        \n",
    "from PIL import Image, ImageTk \n",
    "#img5.show()'''\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img5)\n",
    "plt.savefig('TensorF.png')\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(filepath):\n",
    "    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE) / 255.\n",
    "    res = np.array(classifier.predict(img[np.newaxis, :, :, np.newaxis]))\n",
    "    ans = np.reshape(res, (5, 36))\n",
    "    l_ind = []\n",
    "    probs = []\n",
    "    for a in ans:\n",
    "        l_ind.append(np.argmax(a))\n",
    "        probs.append(np.max(a))\n",
    "\n",
    "    capt = ''\n",
    "    for l in l_ind:\n",
    "        capt += symbols[l]\n",
    "    return capt, sum(probs) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import subprocess\n",
    "\n",
    "def ocr(path):\n",
    "    temp = tempfile.NamedTemporaryFile(delete=False)\n",
    "\n",
    "    process = subprocess.Popen(['tesseract', path, temp.name], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    process.communicate()\n",
    "\n",
    "    with open(temp.name + '.txt', 'r') as handle:\n",
    "        contents = handle.read()\n",
    "\n",
    "    os.remove(temp.name + '.txt')\n",
    "    os.remove(temp.name)\n",
    "\n",
    "    return contents\n",
    "\n",
    "str = ocr('TensorFlowResult.png.png')\n",
    "print(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "\n",
    "im = Image.open(\"TensorFlowResult.png\") # the second one \n",
    "im = im.filter(ImageFilter.MedianFilter())\n",
    "enhancer = ImageEnhance.Contrast(im)\n",
    "im = enhancer.enhance(22)\n",
    "im = im.convert('1')\n",
    "im.save('test2.jpg')\n",
    "\n",
    "text = pytesseract.image_to_string(Image.open('test2.jpg'))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "e078debe659f1ddfd1b2506dcc5fa58c6500a399",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1aa94efd30>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c706b4a269ca5724afe93bf4693ada53d36e1b1b"
   },
   "source": [
    "**We can see that it matches most of the words but sometimes give error in diiferentiation of capital and small letters.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b9dc8536974c70051aa9788fe283fe115468d210"
   },
   "source": [
    "                          - - - - - - - - - - - - -- - - - - - - - - END- - - - - - - - - - - - - - - -- - - - - - - - - - - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_uuid": "aa3ff6f0be68127e9bca0d77a38c27d742aa6206"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from keras.preprocessing.image import img_to_array\\nimport numpy as np \\nlist=[\\'s1\\',\\'s2\\']\\nimage = cv2.imread(\\'../input/picture/main-qimg-03de963368e748a6fb7e399772b09c48-c\\')\\nprint(type(image))\\n# pre-process the image for classification\\nimage = cv2.resize(image, (50,50))\\nima=image\\n\\nimage = image.astype(\"float\") / 255.0\\nimage = img_to_array(image)\\nimage = np.expand_dims(image, axis=0)\\nprint(image.shape)\\n\\npred = classifier.predict(image)[0]\\nfor i in range(2):\\n    if pred[i]>0.5:\\n        print(list[i],(pred[i]).astype(\\'float32\\'))\\n    \\n\\nprint(pred)\\n\\n#classifier.save(\\'../input/model.h5\\')'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from keras.preprocessing.image import img_to_array\n",
    "import numpy as np \n",
    "list=['s1','s2']\n",
    "image = cv2.imread('../input/picture/main-qimg-03de963368e748a6fb7e399772b09c48-c')\n",
    "print(type(image))\n",
    "# pre-process the image for classification\n",
    "image = cv2.resize(image, (50,50))\n",
    "ima=image\n",
    "\n",
    "image = image.astype(\"float\") / 255.0\n",
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "print(image.shape)\n",
    "\n",
    "pred = classifier.predict(image)[0]\n",
    "for i in range(2):\n",
    "    if pred[i]>0.5:\n",
    "        print(list[i],(pred[i]).astype('float32'))\n",
    "    \n",
    "\n",
    "print(pred)\n",
    "\n",
    "#classifier.save('../input/model.h5')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "_uuid": "2a84a101f81fe6287f3d24be1e185d08b79a1153"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import cv2\\nprint((ima.shape))\\n\\ngray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\\nface_cascade = cv2.CascadeClassifier('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/opencv-files/haarcascade_frontalface_alt.xml')\\nfaces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5)\\n(x,y,w,h)=faces[0]\\nimm=gray[y:y+w, x:x+h]\\nprint((gray.shape))\\nimport matplotlib.pyplot as mat\\nmat.plot(imm)\\ncv2.waitKey()\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import cv2\n",
    "print((ima.shape))\n",
    "\n",
    "gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "face_cascade = cv2.CascadeClassifier('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/opencv-files/haarcascade_frontalface_alt.xml')\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5)\n",
    "(x,y,w,h)=faces[0]\n",
    "imm=gray[y:y+w, x:x+h]\n",
    "print((gray.shape))\n",
    "import matplotlib.pyplot as mat\n",
    "mat.plot(imm)\n",
    "cv2.waitKey()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "_uuid": "60dfb948b939843aac837b4f348a7a75d4943510"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import cv2\\nf=[]\\nl=[]\\ndir=sorted(list(os.listdir('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/training-data')))\\nfor i in dir:\\n    s=sorted(list(os.listdir('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/training-data/'+i)))\\n    for j in s:\\n        print(i)\\n        k=cv2.imread('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/training-data/'+i+'/'+j)\\n        gray=cv2.cvtColor(k,cv2.COLOR_BGR2GRAY)\\n        face_cascade=cv2.CascadeClassifier('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/opencv-files/lbpcascade_frontalface.xml')\\n        faces=face_cascade.detectMultiScale(gray,1.2,9)\\n        if len(faces)>0:\\n            (x,y,w,h)=faces[0]\\n            face=gray[y:y+h,x:x+w]\\n            f.append(face)\\n            label=i\\n            if label=='s1':\\n                l.append(1)\\n            else:\\n                l.append(0)\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import cv2\n",
    "f=[]\n",
    "l=[]\n",
    "dir=sorted(list(os.listdir('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/training-data')))\n",
    "for i in dir:\n",
    "    s=sorted(list(os.listdir('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/training-data/'+i)))\n",
    "    for j in s:\n",
    "        print(i)\n",
    "        k=cv2.imread('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/training-data/'+i+'/'+j)\n",
    "        gray=cv2.cvtColor(k,cv2.COLOR_BGR2GRAY)\n",
    "        face_cascade=cv2.CascadeClassifier('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/opencv-files/lbpcascade_frontalface.xml')\n",
    "        faces=face_cascade.detectMultiScale(gray,1.2,9)\n",
    "        if len(faces)>0:\n",
    "            (x,y,w,h)=faces[0]\n",
    "            face=gray[y:y+h,x:x+w]\n",
    "            f.append(face)\n",
    "            label=i\n",
    "            if label=='s1':\n",
    "                l.append(1)\n",
    "            else:\n",
    "                l.append(0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d99d094ecb39942036eb451783589c96a9d189ae"
   },
   "outputs": [],
   "source": [
    "'''face_rec=cv2.face.LBPHFaceRecognizer_create()\n",
    "face_rec.train(f,np.array(l))\n",
    "testimg='../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/test-data/test1.jpg'\n",
    "lab,conf=face_rec.predict(testimg)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
